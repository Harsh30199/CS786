{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ef7fb8",
   "metadata": {
    "id": "49ef7fb8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0f9252",
   "metadata": {
    "id": "2c0f9252"
   },
   "outputs": [],
   "source": [
    "def drawFromADist(p):\n",
    "\n",
    "    if np.sum(p) == 0 :\n",
    "        p = 0.05 * np.ones((1,len(p)))\n",
    "\n",
    "    p = p / (np.sum(p)) ##Transforms values of p such that sum of all values after transforms is 1 and therefore can be used as probability density function\n",
    "    c = np.cumsum(p)   ## Calculates cummulative probability  \n",
    "\n",
    "    idx = np.where((np.random.uniform()- c)<0)\n",
    "    ##print(idx)\n",
    "    sample = np.min(idx)\n",
    "    ##print(p.shape)\n",
    "    out = np.zeros(len(p))\n",
    "    ##print(out)\n",
    "    out[sample] = 1\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee95484",
   "metadata": {
    "id": "6ee95484"
   },
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242f3395",
   "metadata": {
    "id": "242f3395"
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    "    #schedule = sorted(random.sample([i for i in range(1,ENCODING_TIME+1)],N_ITEMS))\n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "##    world_m = np.array(random.choices([i for i in range(1,6)], k = N_WORLD_FEATURES))  ## Initial Feature means % can generate randomly for yourself\n",
    "##    print(world_m)\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    delta = 0.05                      ## % what does this parameter affect? Amount of change in world features values per unit of time \n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*N_WORLD_FEATURES)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "##    if(len(success)==7):\n",
    "##        print(schedule)\n",
    "   \n",
    "    return schedule_load, len(success)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf6041d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daf6041d",
    "outputId": "80253244-c5dd-4e0a-a1ce-0fc8f1dda1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Trial\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  41.666666666666664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Single Trial')\n",
    "schedule_load, nunique = tcm()\n",
    "print('No of unique retrivals :', nunique)\n",
    "print('Scheduling load : ',schedule_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "OajGeq_IEN8_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OajGeq_IEN8_",
    "outputId": "2003ab07-0dee-4bb4-a456-a28b6ee6fbff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple Trial\n",
      "No of unique retrivals for 0 trial  : 8\n",
      "No of unique retrivals for 1 trial  : 8\n",
      "No of unique retrivals for 2 trial  : 9\n",
      "No of unique retrivals for 3 trial  : 9\n",
      "No of unique retrivals for 4 trial  : 8\n",
      "No of unique retrivals for 5 trial  : 6\n",
      "No of unique retrivals for 6 trial  : 8\n",
      "No of unique retrivals for 7 trial  : 7\n",
      "No of unique retrivals for 8 trial  : 8\n",
      "No of unique retrivals for 9 trial  : 7\n",
      "No of unique retrivals for 10 trial  : 6\n",
      "No of unique retrivals for 11 trial  : 8\n",
      "No of unique retrivals for 12 trial  : 6\n",
      "No of unique retrivals for 13 trial  : 8\n",
      "No of unique retrivals for 14 trial  : 8\n",
      "No of unique retrivals for 15 trial  : 7\n",
      "No of unique retrivals for 16 trial  : 7\n",
      "No of unique retrivals for 17 trial  : 9\n",
      "No of unique retrivals for 18 trial  : 7\n",
      "No of unique retrivals for 19 trial  : 8\n",
      "No of unique retrivals for 20 trial  : 7\n",
      "No of unique retrivals for 21 trial  : 7\n",
      "No of unique retrivals for 22 trial  : 6\n",
      "No of unique retrivals for 23 trial  : 7\n",
      "No of unique retrivals for 24 trial  : 7\n",
      "No of unique retrivals for 25 trial  : 7\n",
      "No of unique retrivals for 26 trial  : 7\n",
      "No of unique retrivals for 27 trial  : 6\n",
      "No of unique retrivals for 28 trial  : 7\n",
      "No of unique retrivals for 29 trial  : 7\n",
      "No of unique retrivals for 30 trial  : 8\n",
      "No of unique retrivals for 31 trial  : 7\n",
      "No of unique retrivals for 32 trial  : 8\n",
      "No of unique retrivals for 33 trial  : 7\n",
      "No of unique retrivals for 34 trial  : 7\n",
      "No of unique retrivals for 35 trial  : 8\n",
      "No of unique retrivals for 36 trial  : 7\n",
      "No of unique retrivals for 37 trial  : 8\n",
      "No of unique retrivals for 38 trial  : 8\n",
      "No of unique retrivals for 39 trial  : 7\n",
      "No of unique retrivals for 40 trial  : 8\n",
      "No of unique retrivals for 41 trial  : 9\n",
      "No of unique retrivals for 42 trial  : 8\n",
      "No of unique retrivals for 43 trial  : 9\n",
      "No of unique retrivals for 44 trial  : 7\n",
      "No of unique retrivals for 45 trial  : 7\n",
      "No of unique retrivals for 46 trial  : 8\n",
      "No of unique retrivals for 47 trial  : 7\n",
      "No of unique retrivals for 48 trial  : 7\n",
      "No of unique retrivals for 49 trial  : 8\n",
      "No of unique retrivals for 50 trial  : 8\n",
      "No of unique retrivals for 51 trial  : 7\n",
      "No of unique retrivals for 52 trial  : 7\n",
      "No of unique retrivals for 53 trial  : 7\n",
      "No of unique retrivals for 54 trial  : 6\n",
      "No of unique retrivals for 55 trial  : 8\n",
      "No of unique retrivals for 56 trial  : 7\n",
      "No of unique retrivals for 57 trial  : 9\n",
      "No of unique retrivals for 58 trial  : 6\n",
      "No of unique retrivals for 59 trial  : 7\n",
      "No of unique retrivals for 60 trial  : 6\n",
      "No of unique retrivals for 61 trial  : 7\n",
      "No of unique retrivals for 62 trial  : 6\n",
      "No of unique retrivals for 63 trial  : 7\n",
      "No of unique retrivals for 64 trial  : 7\n",
      "No of unique retrivals for 65 trial  : 7\n",
      "No of unique retrivals for 66 trial  : 8\n",
      "No of unique retrivals for 67 trial  : 7\n",
      "No of unique retrivals for 68 trial  : 8\n",
      "No of unique retrivals for 69 trial  : 8\n",
      "No of unique retrivals for 70 trial  : 7\n",
      "No of unique retrivals for 71 trial  : 6\n",
      "No of unique retrivals for 72 trial  : 8\n",
      "No of unique retrivals for 73 trial  : 8\n",
      "No of unique retrivals for 74 trial  : 8\n",
      "No of unique retrivals for 75 trial  : 7\n",
      "No of unique retrivals for 76 trial  : 6\n",
      "No of unique retrivals for 77 trial  : 7\n",
      "No of unique retrivals for 78 trial  : 7\n",
      "No of unique retrivals for 79 trial  : 7\n",
      "No of unique retrivals for 80 trial  : 8\n",
      "No of unique retrivals for 81 trial  : 7\n",
      "No of unique retrivals for 82 trial  : 7\n",
      "No of unique retrivals for 83 trial  : 8\n",
      "No of unique retrivals for 84 trial  : 9\n",
      "No of unique retrivals for 85 trial  : 7\n",
      "No of unique retrivals for 86 trial  : 7\n",
      "No of unique retrivals for 87 trial  : 7\n",
      "No of unique retrivals for 88 trial  : 7\n",
      "No of unique retrivals for 89 trial  : 7\n",
      "No of unique retrivals for 90 trial  : 8\n",
      "No of unique retrivals for 91 trial  : 8\n",
      "No of unique retrivals for 92 trial  : 8\n",
      "No of unique retrivals for 93 trial  : 8\n",
      "No of unique retrivals for 94 trial  : 7\n",
      "No of unique retrivals for 95 trial  : 9\n",
      "No of unique retrivals for 96 trial  : 7\n",
      "No of unique retrivals for 97 trial  : 7\n",
      "No of unique retrivals for 98 trial  : 8\n",
      "No of unique retrivals for 99 trial  : 7\n",
      "\n",
      "\n",
      "Schedule Load : 41.66666666666667\n",
      "Mean Unique Retrivals : 7.38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"multiple Trial\")  \n",
    "sch = []\n",
    "uniq= []\n",
    "for i in range(100):\n",
    "  schedule_load, nunique = tcm()\n",
    "  sch.append(schedule_load)\n",
    "  uniq.append(nunique)\n",
    "  print('No of unique retrivals for',i,'trial  :', nunique)\n",
    "  \n",
    "print('\\n')\n",
    "print('Schedule Load :',np.mean(sch))\n",
    "print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6009c1",
   "metadata": {
    "id": "9e6009c1"
   },
   "source": [
    "### In above experimentation we get Average Success Retrival rate of approximalety 7.25 to 7.7 and Schedule load of 41.667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54d5b3",
   "metadata": {
    "id": "6b54d5b3"
   },
   "source": [
    "# PART 2 (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37905b59",
   "metadata": {
    "id": "37905b59"
   },
   "outputs": [],
   "source": [
    "def compdelta():\n",
    "    x = [norm(0.2, 0.5), norm(5, 1)]\n",
    "    c = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8802a8af",
   "metadata": {
    "id": "8802a8af"
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*N_WORLD_FEATURES)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071037e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "071037e4",
    "outputId": "024940f1-fe79-48bb-e307-6b58766bba4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Trial\n",
      "No of unique retrivals : 7\n",
      "Scheduling load :  41.666666666666664\n"
     ]
    }
   ],
   "source": [
    "print('Single Trial')\n",
    "schedule_load, nunique = tcm()\n",
    "print('No of unique retrivals :', nunique)\n",
    "print('Scheduling load : ',schedule_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edlPv7OqFA-P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edlPv7OqFA-P",
    "outputId": "cf9a8f20-394c-480d-e01f-ffc565c1d038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Trials\n",
      "\n",
      "\n",
      "Schedule Load : 41.666666666666664\n",
      "Mean Unique Retrivals : 7.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Multiple Trials')\n",
    "uniq= []\n",
    "for i in range(100):\n",
    "    schedule_load, nunique = tcm()\n",
    "    sch = schedule_load\n",
    "    uniq.append(nunique)\n",
    "\n",
    "print('\\n')    \n",
    "print('Schedule Load :',sch)\n",
    "print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16397725",
   "metadata": {
    "id": "16397725"
   },
   "source": [
    "# PART 2 (B) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0a153",
   "metadata": {
    "id": "a7b0a153"
   },
   "source": [
    "### I have assumed independent gaussian models for the mixture from which delta is being sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e609b8",
   "metadata": {
    "id": "c0e609b8"
   },
   "outputs": [],
   "source": [
    "def tcm(schedule):\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    "\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*N_WORLD_FEATURES)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5572a3",
   "metadata": {
    "id": "2e5572a3"
   },
   "source": [
    "### Schedule Load is inversely propptional to median of difference of consecutive items's encoding time, i.e. if the median of difference increases, schedule load will decrease. In our case there are 10 items and therefore 9 differences. To have maximum median of difference we will keep  4 differences to be minimum and  5 differences to be maximum keeping in mind that our average success rate is atleast 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5eb8d87",
   "metadata": {
    "id": "e5eb8d87"
   },
   "outputs": [],
   "source": [
    "def schedulelist():\n",
    "    schlist = []\n",
    "    for s in range(1,11,2):\n",
    "        b = (499-4*s)//5\n",
    "        schlist.append([1,b+1,2*b+1,3*b+1,4*b+1,5*b+1,5*b+1+s,5*b+1+s*2,5*b+1+s*3,5*b+1+s*4])\n",
    "        schlist.append([1,s+1,2*s+1,3*s+1,4*s+1,4*s+1+b,4*s+1+b*2,4*s+1+b*3,4*s+1+b*4,4*s+1+b*5])\n",
    "    schlist = sorted(schlist)\n",
    "    return schlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4ab411",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b4ab411",
    "outputId": "9e21ab8d-9db9-4fb4-d328-29782c005ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Trials \n",
      "\n",
      "\n",
      "Schedule:  [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "No of unique retrivals : 7\n",
      "Scheduling load :  5.05050505050505\n",
      "\n",
      "Schedule:  [1, 2, 3, 4, 5, 104, 203, 302, 401, 500]\n",
      "No of unique retrivals : 6\n",
      "Scheduling load :  5.05050505050505\n",
      "\n",
      "Schedule:  [1, 98, 195, 292, 389, 486, 489, 492, 495, 498]\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  5.154639175257732\n",
      "\n",
      "Schedule:  [1, 4, 7, 10, 13, 110, 207, 304, 401, 498]\n",
      "No of unique retrivals : 6\n",
      "Scheduling load :  5.154639175257732\n",
      "\n",
      "Schedule:  [1, 96, 191, 286, 381, 476, 481, 486, 491, 496]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.2631578947368425\n",
      "\n",
      "Schedule:  [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]\n",
      "No of unique retrivals : 7\n",
      "Scheduling load :  5.2631578947368425\n",
      "\n",
      "Schedule:  [1, 95, 189, 283, 377, 471, 478, 485, 492, 499]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.319148936170213\n",
      "\n",
      "Schedule:  [1, 8, 15, 22, 29, 123, 217, 311, 405, 499]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.319148936170213\n",
      "\n",
      "Schedule:  [1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.434782608695652\n",
      "\n",
      "Schedule:  [1, 10, 19, 28, 37, 129, 221, 313, 405, 497]\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  5.434782608695652\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule with lowest schedule load and average success retrival rate atleast  7\n",
      "Schedule : [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "No of unique retrivals : 7\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "print('Single Trials \\n\\n')\n",
    "for schedule in schlist:\n",
    "    schedule_load, nunique = tcm(schedule)\n",
    "    print('Schedule: ',schedule)\n",
    "    print('No of unique retrivals :', nunique)\n",
    "    print('Scheduling load : ',schedule_load)\n",
    "    print()\n",
    "    if nunique >= 7:\n",
    "        schload.append(schedule_load)\n",
    "        sch.append(schedule)\n",
    "        succ.append(nunique)\n",
    "    \n",
    "print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "minload = np.argmin(schload)\n",
    "print('Schedule :',sch[minload])\n",
    "print('Schedule Load :',schload[minload])\n",
    "print('No of unique retrivals :', succ[minload])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "WaeniG7TFTQi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaeniG7TFTQi",
    "outputId": "84828731-39db-4d54-a694-069ad9f5f866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Multiple Trials \n",
      "\n",
      "\n",
      "Schedule: [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 7.97\n",
      "\n",
      "Schedule: [1, 2, 3, 4, 5, 104, 203, 302, 401, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 5.27\n",
      "\n",
      "Schedule: [1, 98, 195, 292, 389, 486, 489, 492, 495, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 7.98\n",
      "\n",
      "Schedule: [1, 4, 7, 10, 13, 110, 207, 304, 401, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 6.24\n",
      "\n",
      "Schedule: [1, 96, 191, 286, 381, 476, 481, 486, 491, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 8.06\n",
      "\n",
      "Schedule: [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 6.88\n",
      "\n",
      "Schedule: [1, 95, 189, 283, 377, 471, 478, 485, 492, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 8.15\n",
      "\n",
      "Schedule: [1, 8, 15, 22, 29, 123, 217, 311, 405, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 7.53\n",
      "\n",
      "Schedule: [1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 8.06\n",
      "\n",
      "Schedule: [1, 10, 19, 28, 37, 129, 221, 313, 405, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 7.38\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule with lowest schedule load and average success retrival rate atleast  7\n",
      "Schedule : [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean No of unique retrivals : 7.97\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "\n",
    "print('\\n\\n Multiple Trials \\n\\n')\n",
    "     \n",
    "for schedule in schlist: \n",
    "    tempsch = 0\n",
    "    uniq= []\n",
    "    for i in range(100):\n",
    "        schedule_load, nunique = tcm(schedule)\n",
    "        tempsch= schedule_load\n",
    "        uniq.append(nunique)\n",
    "      \n",
    "    print('Schedule:',schedule)\n",
    "    print('Schedule Load :',tempsch)\n",
    "    print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "    print()\n",
    "    if np.mean(uniq) >= 7:\n",
    "        schload.append(schedule_load)\n",
    "        sch.append(schedule)\n",
    "        succ.append(np.mean(uniq))\n",
    "        \n",
    "print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "minload = np.argmin(schload)\n",
    "print('Schedule :',sch[minload])\n",
    "print('Schedule Load :',schload[minload])\n",
    "print('Mean No of unique retrivals :', succ[minload])\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2c22b",
   "metadata": {
    "id": "d7d2c22b"
   },
   "source": [
    "### It is observed after repetitive experimentation with above code that a schedule with \n",
    "\n",
    "#### (i) 5 big differences (in range 92 to 99) at beginning of schedule and 4 small differences (in range 9 to 1) at the end always gives  an average success retrival rate of greater than equal to 7\n",
    "\n",
    "#### [1, 100, 199, 298, 397, 496, 497, 498, 499, 500],[1, 98, 195, 292, 389, 486, 489, 492, 495, 498],[1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
    "\n",
    "#### (ii) 4 small differences (in range 5 to 9) at beginning of schedule and 5 big differences (in range 95 to 92) at end generally gives an averafe success retrival rate of gretaer than equal to 7\n",
    "\n",
    "#### [1, 10, 19, 28, 37, 129, 221, 313, 405, 497] , [1, 8, 15, 22, 29, 123, 217, 311, 405, 499] , [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac916f",
   "metadata": {
    "id": "d5ac916f"
   },
   "source": [
    "# PART 3 (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BxawNYtMFO0b",
   "metadata": {
    "id": "BxawNYtMFO0b"
   },
   "source": [
    "````{div} full-width\n",
    "````\n",
    "## Derivation of E-step and M-step for EM Algorithm on GMM \n",
    "\n",
    "\n",
    "$\\large{\\text{ A Gaussian Mixture Distribution: }}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "p(\\mathbf{x})=\\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(\\mathbf{x} \\mid \\mu_{k}, \\Sigma_{k}\\right)}\n",
    "$$ <br><br>\n",
    "\n",
    "$\\large{\\text{Let } z \\text{ be a latent variable then }}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "z \\sim \\text { Categorical }(\\pi) \\quad \\text { (where } \\pi_{k} \\geq 0, \\quad \\sum_{k} \\pi_{k}=1 \\text { ) }}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Joint Distribution }}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "p(\\mathrm{x}, \\mathrm{z})=p(\\mathrm{z}) p(\\mathrm{x} \\mid \\mathrm{z})}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Let }\\theta \\text{ be set of parameters }\\pi, \\mu, \\Sigma}$ <br><br>\n",
    "\n",
    "$\\large{\\text{Likelihood is }}$ <br><br>\n",
    "\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "L(\\theta \\mid \\mathbf{X})&= p(\\mathbf{X} \\mid \\theta) \\\\ \\\\\n",
    "&=\\prod_{i} p\\left(x_{i} \\mid \\theta\\right) \\\\ \\\\\n",
    "&=\\prod_{i}\\left(\\sum_{k = 1}^{K} \\pi_{k} \\mathrm{~N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Log Likelihood is }}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "\\ell(\\mathbf{X} \\mid \\theta)&=\\ln L(\\mathbf{X} \\mid \\theta)\\\\ \\\\ &=\\sum_{i} \\log \\left(\\sum_{k=1}^{K} \\pi_{k} N\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Jensen's Inequality is }}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\log \\left(\\sum_{k=1}^{K} \\alpha_{k} x_{k}\\right) \\geqslant \\sum_{k=1}^{K} \\alpha_{k} \\log \\left(x_{k}\\right)}\n",
    "$$<br><br>\n",
    "$\\large{\\text{where } \\alpha_{k} \\text{ is weight of point } x_k}$ <br><br>\n",
    "\n",
    "$\\large{\\text{We will use above inequality to define the lower bound on log likelihood which is dependent on } \\theta \\text{ and }E[z_n]}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "\\log \\left(p\\left(x_{i} \\mid \\theta\\right)\\right) &=\\log \\left(\\sum_{k=1}^{K} p\\left(x_{i} \\mid z_{i}=k, \\theta\\right) p\\left(z_{i}=k \\mid \\theta\\right)\\right) \\\\ \\\\\n",
    "&=\\log \\left(\\sum_{k=1}^{K} p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)\\right) \\\\ \\\\\n",
    "&=\\log \\left(\\sum_{k=1}^{K} \\frac{E[z_{ik}]}{E[z_{ik}]} p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)\\right) \\\\ \\\\\n",
    "&=\\log \\left(\\sum_{k=1}^{K} E[z_{ik}] \\frac{p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)}{E[z_{ik}]}\\right)\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Using Jensen's Inequality } }$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "&=\\log \\left(\\sum_{k=1}^{K} E[z_{ik}] \\frac{p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)}{E[z_{ik}]}\\right) \\geqslant \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(\\frac{p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)}{E[z_{ik}]}\\right)\\\\ \\\\\n",
    "&=\\mathcal{L_{i}}(\\theta, E[z_i])\n",
    "\\end{aligned}}\n",
    "$$\n",
    "<br><br>\n",
    "\n",
    "## E Step\n",
    "<br><br>\n",
    "$$\\large{\n",
    "E[z_{ik}]=p\\left(z_{n}=k \\mid x_{n} , \\pi, \\mu, \\Sigma\\right)}\n",
    "$$<br><br>\n",
    "\n",
    "\n",
    "$\\large{\\text{Conditional Probability using Bayes Rule of  }z \\text{ given } x}$ <br><br>\n",
    "\n",
    "$$ \\large{\n",
    "\\begin{aligned}\n",
    "E[z_{ik}]=p(z=k \\mid \\mathbf{x}) &=\\frac{p(z=k) p(\\mathbf{x} \\mid z=k)}{p(\\mathbf{x})} \\\\ \\\\\n",
    "&=\\frac{p(z=k) p(\\mathbf{x} \\mid z=k)}{\\sum_{k=1}^{K} p(z=k) p(\\mathbf{x} \\mid z=k)} \\\\ \\\\\n",
    "&=\\frac{\\pi_{k} \\mathcal{N}\\left(\\mathbf{x} \\mid \\mu_{k}, \\Sigma_{k}\\right)}{\\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(\\mathbf{x} \\mid \\mu_{k}, \\Sigma_{k}\\right)}\n",
    "\\end{aligned}}\n",
    "$$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## M Step\n",
    "<br><br>\n",
    "\n",
    "$\\large{\\text{We fix } E[z_i] \\text{ and maximize the lower bound}}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}(\\theta, E[z_i])&=\\sum_{i} \\sum_{k=1}^{K} E[z_{ik}]\\log \\left(\\frac{p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)}{E[z_{ik}]}\\right) \\\\ \\\\\n",
    "&=\\sum_{i} \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(p\\left(x_{i}, z_{i}=k \\mid \\theta\\right)\\right)-\\sum_{i} \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(E[z_{ik}]\\right)\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Second term in above equation is not dependent on } \\theta }$ <br><br>\n",
    "\n",
    "\n",
    "$$\\large{\n",
    "\\mathcal{L}(\\theta, E[z_i])=\\mathbb{E}_{E[z_i]} \\log P(X, Z \\mid \\theta)}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Now to maximize lower bound we have to find parameter values for which partial derivative respect to them is 0}}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{array}{r}\n",
    "\\max _{\\theta} \\mathcal{L}(\\theta,E[z_{ik}]) \\Leftrightarrow \\nabla_{\\theta} \\mathcal{L}(\\theta, E[z_{ik}])=  0 \\\\ \\\\\n",
    "\\Leftrightarrow\\left\\{\\begin{array}{l}\n",
    "\\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\Sigma_{k}}= 0 \\\\ \\\\\n",
    "\\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\mu_{k}}=0 \\\\ \\\\\n",
    "\\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\pi_{k}}=0\n",
    "\\end{array}\\right.\n",
    "\\end{array}}\n",
    "$$<br><br>\n",
    "\n",
    "\n",
    "$\\large{\\text{First lets compute mean vector } \\mu_k}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{align}\n",
    "& \\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\mu_{k}}=0 \\\\ \\\\ \n",
    "& \\frac{\\partial}{\\partial \\mu_{k}}\\left(\\sum_i \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(\\pi_{k} \\mathrm{~N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\mu_{k}}\\left(\\sum_{i} E[z_{ik}] \\log \\left(\\pi_{k}\\right)+\\sum_{i} E[z_{ik}] \\log \\left(\\mathrm{N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\mu_{k}}\\left(\\sum_{i} E[z_{ik}] \\log \\left(\\frac{1}{(2 \\pi)^{(N / 2)}\\left|\\Sigma_{k}\\right|^{1 / 2}} \\exp \\left(-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right]\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\mu_{k}}\\left(\\sum_{i} E[z_{ik}] \\log \\left(\\frac{1}{(2 \\pi)^{(N / 2)}\\left|\\Sigma_{k}\\right|^{1 / 2}}\\right)+\\sum_{i} E[z_{ik}] \\log \\left(\\exp \\left(-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\sum_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\mu_{k}}\\left(\\sum_{i} E[z_{ik}]\\left(-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\sum_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)=0\n",
    "\\end{align}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Using below mentioned formula about symmetric matrix W , vector x and scalar s}}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\frac{\\partial}{\\partial s}(\\mathbf{x}-s)^{T} \\mathbf{W}(\\mathbf{x}-s)=-2 \\mathbf{W}(\\mathbf{x}-s)}\n",
    "$$<br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{aligned}\n",
    "& \\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\mu_{k}}=0 \\\\ \\\\\n",
    "& \\sum_{i} E[z_{ik}]\\left(-\\frac{1}{2}\\left(-2 \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)=0 \\\\ \\\\ \n",
    "& \\sum_{i} E[z_{ik}] \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)=0 \\\\ \\\\\n",
    "& \\sum_{i} E[z_{ik}] \\Sigma_{k}^{-1} x_{i}-\\sum_{i} E[z_{ik}] \\Sigma_{k}^{-1} \\mu_{k}=0 \\\\ \\\\ \n",
    "& \\mu_{k}= \\frac{ \\sum_{i} E[z_{ik}] \\Sigma_{k}^{-1} x_{i}} {\\sum_{i} E[z_{ik}] \\Sigma_{k}^{-1}} \\\\ \\\\\n",
    "& \\mu_{k}= \\frac {\\sum_{i} E[z_{ik}] x_{i} }{\\sum_i E[z_{ik}]}\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Now lets compute Covariance Matrix } \\Sigma_k}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{align}\n",
    "& \\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\Sigma_{k}}=0 \\\\ \\\\ \n",
    "& \\frac{\\partial}{\\partial \\Sigma_{k}}\\left(\\sum_i \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(\\pi_{k} \\mathrm{~N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\Sigma_{k}}\\left(\\sum_{i} E[z_{ik}]\\log \\left(N\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)=0  \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\Sigma_{k}}\\left(\\sum_{i} E[z_{ik}]\\log \\left(\\frac{1}{(2 \\pi)^{(N / 2)}\\left|\\Sigma_{k}\\right|^{1 / 2}} \\exp \\left(-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\Sigma_{k}}\\left(\\sum_{i} E[z_{ik}]\\left(\\log \\left(\\frac{1}{(2 \\pi)^{(N / 2)}}\\right)+\\frac{1}{2} \\log \\left(\\frac{1}{\\left|\\sum_{k}\\right|}\\right)+\\log \\left(\\exp \\left(-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "& \\frac{\\partial}{\\partial \\Sigma_{k}}\\left(\\sum_{i} E[z_{ik}] \\left(\\frac{1}{2} \\log \\left(\\frac{1}{\\left|\\sum_{k}\\right|}\\right)-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\Sigma_{k}^{-1}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)=0\n",
    "\\end{align}}\n",
    "$$<br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{aligned}\n",
    " \\Sigma_{k}^{-1} &= \\frac{1}{\\sigma_k^2} I \\\\ \\\\\n",
    "\\mid \\Sigma_{k}^{-1} \\mid &= \\sigma_{k}^{-2D}\n",
    "\\end{aligned}}\n",
    "$$<br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{align}\n",
    "& \\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\sigma_{k}}=0 \\\\ \\\\ \n",
    "& \\frac{\\partial}{\\partial \\sigma_{k}}\\left(\\sum_{i} E[z_{ik}] \\left(\\frac{1}{2} \\log \\left(\\frac{1}{\\sigma_{k}^{2D}}\\right)-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\sigma_{k}^{-2}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)=0 \\\\ \\\\ \n",
    "& \\frac{\\partial}{\\partial \\sigma_{k}}\\left(\\sum_{i} E[z_{ik}] \\left(-D \\log \\left(\\sigma_{k}\\right)-\\frac{1}{2}\\left(x_{i}-\\mu_{k}\\right)^{T} \\sigma_{k}^{-2}\\left(x_{i}-\\mu_{k}\\right)\\right)\\right)=0 \\\\ \\\\ \n",
    "& \\sum_{i} E[z_{ik}] \\left(- \\frac {D} {\\sigma_{k}}+\\frac {\\left(x_{i}-\\mu_{k}\\right)^{T} \\left(x_{i}-\\mu_{k}\\right)} {\\sigma_k^3}\\right) = 0 \\\\ \\\\\n",
    "& \\sum_{i} E[z_{ik}] \\left(- D +\\frac {\\left(x_{i}-\\mu_{k}\\right)^{T} \\left(x_{i}-\\mu_{k}\\right)} {\\sigma_k^2}\\right) = 0 \\\\ \\\\\n",
    "& D \\sum_{i} E[z_{ik}] = \\sum_{i} E[z_{ik}] \\left(\\frac {\\left(x_{i}-\\mu_{k}\\right)^{T} \\left(x_{i}-\\mu_{k}\\right)} {\\sigma_k^2}\\right) \\\\ \\\\\n",
    "& {\\sigma_k^2} = \\frac {\\sum_{i} E[z_{ik}] \\quad {\\mid \\mid x_i - \\mu_k \\mid \\mid}^2 } {D \\sum_{i} E[z_{ik}]} \\\\ \\\\\n",
    "\\end{align}}\n",
    "$$<br><br>\n",
    "\n",
    "$\\large{\\text{Now lets compute Weights  } \\pi_k}$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{align}\n",
    "& \\frac{\\partial \\mathcal{L}(\\theta, E[z_{ik}])}{\\partial \\pi_{k}}=0 \\\\ \\\\ \n",
    "& \\frac{\\partial}{\\partial \\pi_{k}}\\left(\\sum_i \\sum_{k=1}^{K} E[z_{ik}] \\log \\left(\\pi_{k} \\mathrm{~N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)=0 \\\\ \\\\\n",
    "&\\frac{\\partial}{\\partial \\pi_k}\\left[\\left(\\sum_{i} E[z_{ik}] \\log \\left(\\pi_{k} \\mathrm{~N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)-\\lambda \\pi_{k}\\right]=0\\\\ \\\\\n",
    "&\\frac{\\partial}{\\partial \\pi_k}\\left[\\left(\\sum_{i} E[z_{ik}] \\log \\left(\\pi_{k}\\right)+\\sum_{i} E[z_{ik}] \\log \\left(\\mathrm{N}\\left(x_{i} \\mid \\mu_{k}, \\Sigma_{k}\\right)\\right)\\right)-\\lambda \\alpha_{k}\\right]=0\\\\ \\\\\n",
    "&\\frac{\\partial}{\\partial \\pi_k}\\left[\\sum_{i} E[z_{ik}] \\log \\left(\\pi_{k}\\right)-\\lambda \\pi_{k}\\right]=0\\\\ \\\\\n",
    "&\\frac{\\sum_{i} E[z_{ik}]}{\\pi_{k}}-\\lambda=0\\\\ \\\\\n",
    "&\\pi_{k}=\\frac{\\sum_{i}E[z_{ik}]}{\\lambda}\n",
    "\\end{align}}\n",
    "$$\n",
    "<br><br>\n",
    "\n",
    "$\\large{\\text{Now to get rid of  } \\lambda \\text{ we use the mixture weight constraint} }$ <br><br>\n",
    "\n",
    "$$\\large{\n",
    "\\begin{align}\n",
    "&\\sum_{k=1}^{K} \\pi_{k}= 1 \\\\ \\\\\n",
    "&\\sum_{k=1}^{K} \\frac{\\sum_{i} E[z_{ik}]}{\\lambda}=1 \\\\ \\\\\n",
    "&\\frac{\\sum_{k=1}^{K} \\sum_{i} E[z_{ik}]}{\\lambda}=1\\\\ \\\\\n",
    "&\\lambda =\\sum_{k=1}^{K} \\sum_{i} E[z_{ik}] \\\\ \\\\\n",
    "\\end{align}}\n",
    "$$\n",
    "\n",
    "$\\large{\\text{Substituting this in previous equation } }$ <br><br>\n",
    "\n",
    "$$ \\large{\n",
    "\\pi_{k}=\\frac{\\sum_{i}E[z_{ik}]}{\\sum_{k=1}^{K} \\sum_{i} E[z_{ik}]}}\n",
    "$$ <br><br>\n",
    "### Parameter  Updation :\n",
    "\n",
    "$$\\large{\\mu_{k}= \\frac {\\sum_{i} E[z_{ik}] x_{i} }{\\sum_i E[z_{ik}]}} $$<br><br>\n",
    "\n",
    "$$ \\large{{\\sigma_k^2} = \\frac {\\sum_{i} E[z_{ik}] \\quad {\\mid \\mid x_i - \\mu_k \\mid \\mid}^2 } {D \\sum_{i} E[z_{ik}]}} $$<br><br>\n",
    "\n",
    "$$ \\large{\\Sigma_k} = \\sigma_k^2 I $$<br><br>\n",
    "\n",
    "$$ \\large{\n",
    "\\pi_{k}=\\frac{\\sum_{i}E[z_{ik}]}{\\sum_{k=1}^{K} \\sum_{i} E[z_{ik}]}}\n",
    "$$<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7377b26",
   "metadata": {
    "id": "b7377b26"
   },
   "outputs": [],
   "source": [
    "def compdelta(): ##Samples original GMM \n",
    "    x = [norm(0.2, 0.5), norm(5, 1)]\n",
    "    c = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f4e762",
   "metadata": {
    "id": "67f4e762"
   },
   "outputs": [],
   "source": [
    "def compdelta2(m1,v1,w1,m2,v2,w2): ##Samples Estimated GMM using EM Algorithm\n",
    "    x = [norm(m1, v1), norm(m2, v2)]\n",
    "    c = np.random.choice([0, 1], p=[w1, w2])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b57cde",
   "metadata": {
    "id": "72b57cde"
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "    ogdelta = []\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        ogdelta.append(delta)\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "   \n",
    "    ogdelta = np.array([[o] for o in ogdelta])       \n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='spherical',tol=1e-10,weights_init = [0.5,0.5], means_init = [[0],[3]],precisions_init = [0.25,0.75])\n",
    "    gmm.fit(ogdelta)\n",
    "    mu = gmm.means_\n",
    "    var = gmm.covariances_\n",
    "    w = gmm.weights_\n",
    "\n",
    " \n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        delta = compdelta2(mu[0],var[0],w[0],mu[1],var[1],w[1])\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca8289f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fca8289f",
    "outputId": "47ab3164-d3f8-44c3-b85b-a2a95fb521e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Single Trial \n",
      "\n",
      "\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  41.666666666666664\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n Single Trial \\n\\n')\n",
    "schedule_load, nunique = tcm()\n",
    "print('No of unique retrivals :', nunique)\n",
    "print('Scheduling load : ',schedule_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "K4pjxBZoGAkc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4pjxBZoGAkc",
    "outputId": "f168f4f6-1b4a-4e12-dbbb-647df1dbb1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Multiple Trials\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule Load : 41.666666666666664\n",
      "Mean Unique Retrivals : 7.74\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n Multiple Trials\\n\\n')\n",
    "\n",
    "uniq= []\n",
    "for i in range(100):\n",
    "    schedule_load, nunique = tcm()\n",
    "    sch = schedule_load\n",
    "    uniq.append(nunique)\n",
    "\n",
    "print('\\n')    \n",
    "print('Schedule Load :',sch)\n",
    "print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "\n",
    "\n",
    "##% humans can retrieve about 7 items effectively from memory. get this model\n",
    "##% to behave like humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0076882",
   "metadata": {
    "id": "f0076882"
   },
   "source": [
    "# PART 3 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2554e3",
   "metadata": {
    "id": "3a2554e3"
   },
   "outputs": [],
   "source": [
    "def schedulelist():\n",
    "    schlist = []\n",
    "    for s in range(1,11,2):\n",
    "        b = (499-4*s)//5\n",
    "        schlist.append([1,b+1,2*b+1,3*b+1,4*b+1,5*b+1,5*b+1+s,5*b+1+s*2,5*b+1+s*3,5*b+1+s*4])\n",
    "        schlist.append([1,s+1,2*s+1,3*s+1,4*s+1,4*s+1+b,4*s+1+b*2,4*s+1+b*3,4*s+1+b*4,4*s+1+b*5])\n",
    "\n",
    "    return schlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e53723",
   "metadata": {
    "id": "44e53723"
   },
   "outputs": [],
   "source": [
    "def tcm(schedule):\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    \n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "    ogdelta = []\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        ogdelta.append(delta)\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "    \n",
    "    ogdelta = np.array([[o] for o in ogdelta])       \n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='spherical',tol=1e-10,weights_init = [0.5,0.5], means_init = [[0],[3]],precisions_init = [0.25,0.75])\n",
    "    gmm.fit(ogdelta)\n",
    "    mu = gmm.means_\n",
    "    var = gmm.covariances_\n",
    "    w = gmm.weights_\n",
    "\n",
    "\n",
    " \n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        delta = compdelta2(mu[0],var[0],w[0],mu[1],var[1],w[1])\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f97a3da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f97a3da",
    "outputId": "aeea4080-c312-4a63-e74c-d7a1a7e1954c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Single Trial \n",
      "\n",
      "\n",
      "Schedule:  [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.05050505050505\n",
      "\n",
      "Schedule:  [1, 2, 3, 4, 5, 104, 203, 302, 401, 500]\n",
      "No of unique retrivals : 4\n",
      "Scheduling load :  5.05050505050505\n",
      "\n",
      "Schedule:  [1, 98, 195, 292, 389, 486, 489, 492, 495, 498]\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  5.154639175257732\n",
      "\n",
      "Schedule:  [1, 4, 7, 10, 13, 110, 207, 304, 401, 498]\n",
      "No of unique retrivals : 5\n",
      "Scheduling load :  5.154639175257732\n",
      "\n",
      "Schedule:  [1, 96, 191, 286, 381, 476, 481, 486, 491, 496]\n",
      "No of unique retrivals : 7\n",
      "Scheduling load :  5.2631578947368425\n",
      "\n",
      "Schedule:  [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  5.2631578947368425\n",
      "\n",
      "Schedule:  [1, 95, 189, 283, 377, 471, 478, 485, 492, 499]\n",
      "No of unique retrivals : 7\n",
      "Scheduling load :  5.319148936170213\n",
      "\n",
      "Schedule:  [1, 8, 15, 22, 29, 123, 217, 311, 405, 499]\n",
      "No of unique retrivals : 6\n",
      "Scheduling load :  5.319148936170213\n",
      "\n",
      "Schedule:  [1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
      "No of unique retrivals : 9\n",
      "Scheduling load :  5.434782608695652\n",
      "\n",
      "Schedule:  [1, 10, 19, 28, 37, 129, 221, 313, 405, 497]\n",
      "No of unique retrivals : 8\n",
      "Scheduling load :  5.434782608695652\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule with lowest schedule load and average success retrival rate atleast  7\n",
      "Schedule : [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "No of unique retrivals : 8\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "print('\\n\\n Single Trial \\n\\n')\n",
    "for schedule in schlist:\n",
    "    schedule_load, nunique = tcm(schedule)\n",
    "    print('Schedule: ',schedule)\n",
    "    print('No of unique retrivals :', nunique)\n",
    "    print('Scheduling load : ',schedule_load)\n",
    "    print()\n",
    "    if nunique >= 7:\n",
    "        schload.append(schedule_load)\n",
    "        sch.append(schedule)\n",
    "        succ.append(nunique)\n",
    "    \n",
    "print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "minload = np.argmin(schload)\n",
    "print('Schedule :',sch[minload])\n",
    "print('Schedule Load :',schload[minload])\n",
    "print('No of unique retrivals :', succ[minload])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Mf-_384hGX6Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mf-_384hGX6Q",
    "outputId": "2a50cf8a-a4a4-4e90-b694-83afdbdc7584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Multiple Trials \n",
      "\n",
      "\n",
      "Schedule: [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 7.88\n",
      "\n",
      "Schedule: [1, 2, 3, 4, 5, 104, 203, 302, 401, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 5.35\n",
      "\n",
      "Schedule: [1, 98, 195, 292, 389, 486, 489, 492, 495, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 7.91\n",
      "\n",
      "Schedule: [1, 4, 7, 10, 13, 110, 207, 304, 401, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 6.5\n",
      "\n",
      "Schedule: [1, 96, 191, 286, 381, 476, 481, 486, 491, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 7.92\n",
      "\n",
      "Schedule: [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 7.0\n",
      "\n",
      "Schedule: [1, 95, 189, 283, 377, 471, 478, 485, 492, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 8.04\n",
      "\n",
      "Schedule: [1, 8, 15, 22, 29, 123, 217, 311, 405, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 7.22\n",
      "\n",
      "Schedule: [1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 7.94\n",
      "\n",
      "Schedule: [1, 10, 19, 28, 37, 129, 221, 313, 405, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 7.42\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule with lowest schedule load and average success retrival rate atleast  7\n",
      "Schedule : [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean No of unique retrivals : 7.88\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "print('\\n\\n Multiple Trials \\n\\n')\n",
    "\n",
    "     \n",
    "for schedule in schlist: \n",
    "    tempsch = 0\n",
    "    uniq= []\n",
    "    for i in range(100):\n",
    "        schedule_load, nunique = tcm(schedule)\n",
    "        tempsch= schedule_load\n",
    "        uniq.append(nunique)\n",
    "      \n",
    "    print('Schedule:',schedule)\n",
    "    print('Schedule Load :',tempsch)\n",
    "    print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "    print()\n",
    "    if np.mean(uniq) >= 7:\n",
    "      schload.append(schedule_load)\n",
    "      sch.append(schedule)\n",
    "      succ.append(np.mean(uniq))\n",
    "        \n",
    "print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "minload = np.argmin(schload)\n",
    "print('Schedule :',sch[minload])\n",
    "print('Schedule Load :',schload[minload])\n",
    "print('Mean No of unique retrivals :', succ[minload])\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c5cf2",
   "metadata": {
    "id": "d73c5cf2"
   },
   "source": [
    "### It is observed after repetitive experimentation with above code that a schedule with \n",
    "\n",
    "#### (i) 5 big differences (in range 92 to 99) at beginning of schedule and 4 small differences (in range 9 to 1) at the end always gives  an average success retrival rate of greater than equal to 7\n",
    "\n",
    "#### [1, 100, 199, 298, 397, 496, 497, 498, 499, 500] gives average success rate above 7 in most iterations\n",
    "\n",
    "#### (ii) 4 small differences (in range 5 to 9) at beginning of schedule and 5 big differences (in range 95 to 92) at end generally gives an average success retrival rate of gretaer than equal to 7\n",
    "\n",
    "#### [1, 10, 19, 28, 37, 129, 221, 313, 405, 497] gives average success rate above 7 in most iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qsyFUkNoBtei",
   "metadata": {
    "id": "qsyFUkNoBtei"
   },
   "source": [
    "# References\n",
    "\n",
    "1. [A Distributed Representation of Temporal Context](https://www.sciencedirect.com/science/article/abs/pii/S0022249601913884)\n",
    "\n",
    "2. [Gaussian Mixture Model](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)\n",
    "\n",
    "3. StackOverflow"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS786 Assignment3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
