{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ef7fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:15.474919Z",
     "start_time": "2022-04-03T18:41:02.861260Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0f9252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:15.507858Z",
     "start_time": "2022-04-03T18:41:15.478692Z"
    }
   },
   "outputs": [],
   "source": [
    "def drawFromADist(p):\n",
    "\n",
    "    if np.sum(p) == 0 :\n",
    "        p = 0.05 * np.ones((1,len(p)))\n",
    "\n",
    "    p = p / (np.sum(p))\n",
    "    c = np.cumsum(p)\n",
    "\n",
    "    idx = np.where((np.random.uniform()- c)<0)\n",
    "    ##print(idx)\n",
    "    sample = np.min(idx)\n",
    "    ##print(p.shape)\n",
    "    out = np.zeros(len(p))\n",
    "    ##print(out)\n",
    "    out[sample] = 1\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee95484",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242f3395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:15.556516Z",
     "start_time": "2022-04-03T18:41:15.513561Z"
    }
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    "    #schedule = sorted(random.sample([i for i in range(1,ENCODING_TIME+1)],N_ITEMS))\n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "##    world_m = np.array(random.choices([i for i in range(1,6)], k = N_WORLD_FEATURES))  ## Initial Feature means % can generate randomly for yourself\n",
    "##    print(world_m)\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    delta = 0.05                      ## % what does this parameter affect? Amount of change in world features values per unit of time \n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "##    if(len(success)==7):\n",
    "##        print(schedule)\n",
    "   \n",
    "    return schedule_load, len(success)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf6041d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:22.718953Z",
     "start_time": "2022-04-03T18:41:15.564677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Single Trial \n",
      "2. Multiple Trials \n",
      "2\n",
      "No of unique retrivals for 0 trial  : 7\n",
      "No of unique retrivals for 1 trial  : 8\n",
      "No of unique retrivals for 2 trial  : 7\n",
      "No of unique retrivals for 3 trial  : 6\n",
      "No of unique retrivals for 4 trial  : 8\n",
      "No of unique retrivals for 5 trial  : 8\n",
      "No of unique retrivals for 6 trial  : 7\n",
      "No of unique retrivals for 7 trial  : 7\n",
      "No of unique retrivals for 8 trial  : 8\n",
      "No of unique retrivals for 9 trial  : 6\n",
      "No of unique retrivals for 10 trial  : 8\n",
      "No of unique retrivals for 11 trial  : 7\n",
      "No of unique retrivals for 12 trial  : 9\n",
      "No of unique retrivals for 13 trial  : 6\n",
      "No of unique retrivals for 14 trial  : 7\n",
      "No of unique retrivals for 15 trial  : 8\n",
      "No of unique retrivals for 16 trial  : 7\n",
      "No of unique retrivals for 17 trial  : 8\n",
      "No of unique retrivals for 18 trial  : 9\n",
      "No of unique retrivals for 19 trial  : 8\n",
      "No of unique retrivals for 20 trial  : 9\n",
      "No of unique retrivals for 21 trial  : 8\n",
      "No of unique retrivals for 22 trial  : 6\n",
      "No of unique retrivals for 23 trial  : 7\n",
      "No of unique retrivals for 24 trial  : 6\n",
      "No of unique retrivals for 25 trial  : 7\n",
      "No of unique retrivals for 26 trial  : 8\n",
      "No of unique retrivals for 27 trial  : 7\n",
      "No of unique retrivals for 28 trial  : 8\n",
      "No of unique retrivals for 29 trial  : 6\n",
      "No of unique retrivals for 30 trial  : 9\n",
      "No of unique retrivals for 31 trial  : 6\n",
      "No of unique retrivals for 32 trial  : 8\n",
      "No of unique retrivals for 33 trial  : 8\n",
      "No of unique retrivals for 34 trial  : 7\n",
      "No of unique retrivals for 35 trial  : 6\n",
      "No of unique retrivals for 36 trial  : 6\n",
      "No of unique retrivals for 37 trial  : 6\n",
      "No of unique retrivals for 38 trial  : 6\n",
      "No of unique retrivals for 39 trial  : 9\n",
      "No of unique retrivals for 40 trial  : 7\n",
      "No of unique retrivals for 41 trial  : 7\n",
      "No of unique retrivals for 42 trial  : 9\n",
      "No of unique retrivals for 43 trial  : 9\n",
      "No of unique retrivals for 44 trial  : 7\n",
      "No of unique retrivals for 45 trial  : 7\n",
      "No of unique retrivals for 46 trial  : 7\n",
      "No of unique retrivals for 47 trial  : 6\n",
      "No of unique retrivals for 48 trial  : 7\n",
      "No of unique retrivals for 49 trial  : 7\n",
      "No of unique retrivals for 50 trial  : 6\n",
      "No of unique retrivals for 51 trial  : 6\n",
      "No of unique retrivals for 52 trial  : 7\n",
      "No of unique retrivals for 53 trial  : 8\n",
      "No of unique retrivals for 54 trial  : 7\n",
      "No of unique retrivals for 55 trial  : 9\n",
      "No of unique retrivals for 56 trial  : 9\n",
      "No of unique retrivals for 57 trial  : 7\n",
      "No of unique retrivals for 58 trial  : 6\n",
      "No of unique retrivals for 59 trial  : 8\n",
      "No of unique retrivals for 60 trial  : 7\n",
      "No of unique retrivals for 61 trial  : 8\n",
      "No of unique retrivals for 62 trial  : 6\n",
      "No of unique retrivals for 63 trial  : 6\n",
      "No of unique retrivals for 64 trial  : 9\n",
      "No of unique retrivals for 65 trial  : 8\n",
      "No of unique retrivals for 66 trial  : 6\n",
      "No of unique retrivals for 67 trial  : 8\n",
      "No of unique retrivals for 68 trial  : 7\n",
      "No of unique retrivals for 69 trial  : 9\n",
      "No of unique retrivals for 70 trial  : 8\n",
      "No of unique retrivals for 71 trial  : 7\n",
      "No of unique retrivals for 72 trial  : 7\n",
      "No of unique retrivals for 73 trial  : 7\n",
      "No of unique retrivals for 74 trial  : 7\n",
      "No of unique retrivals for 75 trial  : 7\n",
      "No of unique retrivals for 76 trial  : 7\n",
      "No of unique retrivals for 77 trial  : 6\n",
      "No of unique retrivals for 78 trial  : 7\n",
      "No of unique retrivals for 79 trial  : 7\n",
      "No of unique retrivals for 80 trial  : 6\n",
      "No of unique retrivals for 81 trial  : 8\n",
      "No of unique retrivals for 82 trial  : 7\n",
      "No of unique retrivals for 83 trial  : 6\n",
      "No of unique retrivals for 84 trial  : 8\n",
      "No of unique retrivals for 85 trial  : 6\n",
      "No of unique retrivals for 86 trial  : 8\n",
      "No of unique retrivals for 87 trial  : 7\n",
      "No of unique retrivals for 88 trial  : 8\n",
      "No of unique retrivals for 89 trial  : 8\n",
      "No of unique retrivals for 90 trial  : 9\n",
      "No of unique retrivals for 91 trial  : 7\n",
      "No of unique retrivals for 92 trial  : 9\n",
      "No of unique retrivals for 93 trial  : 9\n",
      "No of unique retrivals for 94 trial  : 7\n",
      "No of unique retrivals for 95 trial  : 7\n",
      "No of unique retrivals for 96 trial  : 7\n",
      "No of unique retrivals for 97 trial  : 6\n",
      "No of unique retrivals for 98 trial  : 8\n",
      "No of unique retrivals for 99 trial  : 7\n",
      "\n",
      "\n",
      "Schedule Load : 41.66666666666667\n",
      "Mean Unique Retrivals : 7.3\n"
     ]
    }
   ],
   "source": [
    "ch = input('1. Single Trial \\n2. Multiple Trials \\n')\n",
    "\n",
    "if(ch == '1'):\n",
    "    schedule_load, nunique = tcm()\n",
    "    print('No of unique retrivals :', nunique)\n",
    "    print('Scheduling load : ',schedule_load)\n",
    "\n",
    "elif(ch == '2'):\n",
    "     \n",
    "     sch = []\n",
    "     uniq= []\n",
    "     for i in range(100):\n",
    "         schedule_load, nunique = tcm()\n",
    "         sch.append(schedule_load)\n",
    "         uniq.append(nunique)\n",
    "         print('No of unique retrivals for',i,'trial  :', nunique)\n",
    "         \n",
    "     print('\\n')\n",
    "     print('Schedule Load :',np.mean(sch))\n",
    "     print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "         \n",
    "else:\n",
    "    print('Invalid Choice')\n",
    "\n",
    "###% humans can retrieve about 7 items effectively from memory. get this model % to behave like humans'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6009c1",
   "metadata": {},
   "source": [
    "### In above experimentation we get Average Success Retrival rate of approximalety 7.25 to 7.7 and Schedule load of 41.667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54d5b3",
   "metadata": {},
   "source": [
    "# PART 2 (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37905b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:22.749708Z",
     "start_time": "2022-04-03T18:41:22.725795Z"
    }
   },
   "outputs": [],
   "source": [
    "def compdelta():\n",
    "    x = [norm(0.2, 0.5), norm(5, 1)]\n",
    "    c = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8802a8af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:41:22.802099Z",
     "start_time": "2022-04-03T18:41:22.757016Z"
    }
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071037e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:44:36.279812Z",
     "start_time": "2022-04-03T18:41:22.809260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Single Trial \n",
      "2. Multiple Trials \n",
      "2\n",
      "\n",
      "\n",
      "Schedule Load : 41.666666666666664\n",
      "Mean Unique Retrivals : 7.77\n"
     ]
    }
   ],
   "source": [
    "ch = input('1. Single Trial \\n2. Multiple Trials \\n')\n",
    "\n",
    "if(ch == '1'):\n",
    "    schedule_load, nunique = tcm()\n",
    "    print('No of unique retrivals :', nunique)\n",
    "    print('Scheduling load : ',schedule_load)\n",
    "\n",
    "elif(ch == '2'):\n",
    "\n",
    "     uniq= []\n",
    "     for i in range(100):\n",
    "         schedule_load, nunique = tcm()\n",
    "         sch = schedule_load\n",
    "         uniq.append(nunique)\n",
    "     \n",
    "     print('\\n')    \n",
    "     print('Schedule Load :',sch)\n",
    "     print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "         \n",
    "else:\n",
    "    print('Invalid Choice')\n",
    "\n",
    "##% humans can retrieve about 7 items effectively from memory. get this model\n",
    "##% to behave like humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16397725",
   "metadata": {},
   "source": [
    "# PART 2 (B) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0a153",
   "metadata": {},
   "source": [
    "### I have assumed independent gaussian models for the mixture from which delta is being sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e609b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:44:36.338442Z",
     "start_time": "2022-04-03T18:44:36.288421Z"
    }
   },
   "outputs": [],
   "source": [
    "def tcm(schedule):\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    "\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "\n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        \n",
    "    ##% the state of the world is the retrieval cue\n",
    "        delta = compdelta()\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5572a3",
   "metadata": {},
   "source": [
    "### Schedule Load is inversely propptional to median of difference of consecutive items's encoding time, i.e. if the median of difference increases, schedule load will decrease. In our case there are 10 items and therefore 9 differences. To have maximum median of difference we will keep  4 differences to be minimum and  5 differences to be maximum keeping in mind that our average success rate is atleast 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eb8d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T18:44:36.366199Z",
     "start_time": "2022-04-03T18:44:36.344004Z"
    }
   },
   "outputs": [],
   "source": [
    "def schedulelist():\n",
    "    schlist = []\n",
    "    for small in range(1,11,2):\n",
    "        big = (499-4*small)//5\n",
    "        schlist.append([1,big+1,2*big+1,3*big+1,4*big+1,5*big+1,5*big+1+small,5*big+1+small*2,5*big+1+small*3,5*big+1+small*4])\n",
    "        schlist.append([1,small+1,2*small+1,3*small+1,4*small+1,4*small+1+big,4*small+1+big*2,4*small+1+big*3,4*small+1+big*4,4*small+1+big*5])\n",
    "\n",
    "    return schlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4ab411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T19:26:38.598713Z",
     "start_time": "2022-04-03T18:44:36.372166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Single Trial \n",
      "2. Multiple Trials \n",
      "2\n",
      "\n",
      "Schedule: [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 7.95\n",
      "\n",
      "Schedule: [1, 2, 3, 4, 5, 104, 203, 302, 401, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean Unique Retrivals : 5.38\n",
      "\n",
      "Schedule: [1, 98, 195, 292, 389, 486, 489, 492, 495, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 7.92\n",
      "\n",
      "Schedule: [1, 4, 7, 10, 13, 110, 207, 304, 401, 498]\n",
      "Schedule Load : 5.154639175257732\n",
      "Mean Unique Retrivals : 6.24\n",
      "\n",
      "Schedule: [1, 96, 191, 286, 381, 476, 481, 486, 491, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 7.98\n",
      "\n",
      "Schedule: [1, 6, 11, 16, 21, 116, 211, 306, 401, 496]\n",
      "Schedule Load : 5.2631578947368425\n",
      "Mean Unique Retrivals : 7.01\n",
      "\n",
      "Schedule: [1, 95, 189, 283, 377, 471, 478, 485, 492, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 8.16\n",
      "\n",
      "Schedule: [1, 8, 15, 22, 29, 123, 217, 311, 405, 499]\n",
      "Schedule Load : 5.319148936170213\n",
      "Mean Unique Retrivals : 7.3\n",
      "\n",
      "Schedule: [1, 93, 185, 277, 369, 461, 470, 479, 488, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 8.06\n",
      "\n",
      "Schedule: [1, 10, 19, 28, 37, 129, 221, 313, 405, 497]\n",
      "Schedule Load : 5.434782608695652\n",
      "Mean Unique Retrivals : 7.51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule with lowest schedule load and average success retrival rate atleast  7\n",
      "Schedule : [1, 100, 199, 298, 397, 496, 497, 498, 499, 500]\n",
      "Schedule Load : 5.05050505050505\n",
      "Mean No of unique retrivals : 7.95\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "ch = input('1. Single Trial \\n2. Multiple Trials \\n')\n",
    "print()\n",
    "if(ch == '1'):\n",
    "    for schedule in schlist:\n",
    "        schedule_load, nunique = tcm(schedule)\n",
    "        print('Schedule: ',schedule)\n",
    "        print('No of unique retrivals :', nunique)\n",
    "        print('Scheduling load : ',schedule_load)\n",
    "        print()\n",
    "        if nunique >= 7:\n",
    "            schload.append(schedule_load)\n",
    "            sch.append(schedule)\n",
    "            succ.append(nunique)\n",
    "        \n",
    "    print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "    minload = np.argmin(schload)\n",
    "    print('Schedule :',sch[minload])\n",
    "    print('Schedule Load :',schload[minload])\n",
    "    print('No of unique retrivals :', succ[minload])\n",
    "        \n",
    "\n",
    "elif(ch == '2'):\n",
    "     \n",
    "    for schedule in schlist: \n",
    "        tempsch = 0\n",
    "        uniq= []\n",
    "        for i in range(100):\n",
    "            schedule_load, nunique = tcm(schedule)\n",
    "            tempsch= schedule_load\n",
    "            uniq.append(nunique)\n",
    "         \n",
    "        print('Schedule:',schedule)\n",
    "        print('Schedule Load :',tempsch)\n",
    "        print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "        print()\n",
    "        if np.mean(uniq) >= 7:\n",
    "            schload.append(schedule_load)\n",
    "            sch.append(schedule)\n",
    "            succ.append(np.mean(uniq))\n",
    "            \n",
    "    print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "    minload = np.argmin(schload)\n",
    "    print('Schedule :',sch[minload])\n",
    "    print('Schedule Load :',schload[minload])\n",
    "    print('Mean No of unique retrivals :', succ[minload])\n",
    "         \n",
    "else:\n",
    "    print('Invalid Choice')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2c22b",
   "metadata": {},
   "source": [
    "### It is observed after repetitive experimentation with above code that a schedule with \n",
    "\n",
    "#### (i) 5 big differences (in range 91 to 95) at beginning of schedule and 4 small differences (in range 10 to 5) at the end generally gives  an average success retrival rate of greater than equal to 7\n",
    "\n",
    "#### [1, 96, 191, 286, 381, 476, 481, 486, 491, 496],[1, 95, 189, 283, 377, 471, 478, 485, 492, 499],[1, 92, 183, 274, 365, 456, 466, 476, 486,496]\n",
    "\n",
    "#### (ii) 4 small differences (in range 7 to 10) at beginning of schedule and 5 big differences (in range 95 to 91) at end generally gives an averafe success retrival rate of gretaer than equal to 7\n",
    "\n",
    "#### [1, 8, 15, 22, 29, 123, 217, 311, 405, 499] , [1, 9, 17, 25, 33, 126, 219, 312, 405, 498] , [1, 11, 21, 31, 41, 132, 223, 314, 405, 496]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac916f",
   "metadata": {},
   "source": [
    "# PART 3 (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2d863",
   "metadata": {},
   "source": [
    "### I have assumed independent gaussian models for the mixture from which delta is being sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7377b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T19:26:38.613674Z",
     "start_time": "2022-04-03T19:26:38.600707Z"
    }
   },
   "outputs": [],
   "source": [
    "def compdelta(): ##Samples original GMM \n",
    "    x = [norm(0.2, 0.5), norm(5, 1)]\n",
    "    c = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f4e762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T19:26:38.629629Z",
     "start_time": "2022-04-03T19:26:38.614672Z"
    }
   },
   "outputs": [],
   "source": [
    "def compdelta2(m1,v1,w1,m2,v2,w2): ##Samples Estimated GMM using EM Algorithm\n",
    "    x = [norm(m1, v1), norm(m2, v2)]\n",
    "    c = np.random.choice([0, 1], p=[w1, w2])\n",
    "    return x[c].rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b57cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T19:26:38.660549Z",
     "start_time": "2022-04-03T19:26:38.631624Z"
    }
   },
   "outputs": [],
   "source": [
    "def tcm():\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    schedule = [2, 14, 25, 61, 153, 261, 269, 272, 462, 464] ## Fixed Schedule for which we get almost average success rate of 7\n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "    ogdelta = []\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        ogdelta.append(delta)\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "    ogdelta = np.array([[o] for o in ogdelta])       \n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='spherical',tol=1e-10,weights_init = [0.5,0.5], means_init = [[0],[3]],precisions_init = [0.25,0.75])\n",
    "    gmm.fit(ogdelta)\n",
    "    mu = gmm.means_\n",
    "    var = gmm.covariances_\n",
    "    w = gmm.weights_\n",
    " \n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        delta = compdelta2(mu[0],var[0],w[0],mu[1],var[1],w[1])\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca8289f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T20:13:17.173253Z",
     "start_time": "2022-04-03T19:26:38.662541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Single Trial \n",
      "2. Multiple Trials \n",
      "2\n",
      "\n",
      "\n",
      "Schedule Load : 41.666666666666664\n",
      "Mean Unique Retrivals : 7.71\n"
     ]
    }
   ],
   "source": [
    "ch = input('1. Single Trial \\n2. Multiple Trials \\n')\n",
    "\n",
    "if(ch == '1'):\n",
    "    schedule_load, nunique = tcm()\n",
    "    print('No of unique retrivals :', nunique)\n",
    "    print('Scheduling load : ',schedule_load)\n",
    "\n",
    "elif(ch == '2'):\n",
    "\n",
    "     uniq= []\n",
    "     for i in range(100):\n",
    "         schedule_load, nunique = tcm()\n",
    "         sch = schedule_load\n",
    "         uniq.append(nunique)\n",
    "     \n",
    "     print('\\n')    \n",
    "     print('Schedule Load :',sch)\n",
    "     print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "         \n",
    "else:\n",
    "    print('Invalid Choice')\n",
    "\n",
    "##% humans can retrieve about 7 items effectively from memory. get this model\n",
    "##% to behave like humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0076882",
   "metadata": {},
   "source": [
    "# PART 3 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2554e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T20:13:17.189211Z",
     "start_time": "2022-04-03T20:13:17.176246Z"
    }
   },
   "outputs": [],
   "source": [
    "def schedulelist():\n",
    "    schlist = []\n",
    "    for small in range(1,11,2):\n",
    "        big = (499-4*small)//5\n",
    "        schlist.append([1,big+1,2*big+1,3*big+1,4*big+1,5*big+1,5*big+1+small,5*big+1+small*2,5*big+1+small*3,5*big+1+small*4])\n",
    "        schlist.append([1,small+1,2*small+1,3*small+1,4*small+1,4*small+1+big,4*small+1+big*2,4*small+1+big*3,4*small+1+big*4,4*small+1+big*5])\n",
    "\n",
    "    return schlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44e53723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T20:13:17.221124Z",
     "start_time": "2022-04-03T20:13:17.194197Z"
    }
   },
   "outputs": [],
   "source": [
    "def tcm(schedule):\n",
    "    N_WORLD_FEATURES = 5\n",
    "    N_ITEMS = 10\n",
    "    ENCODING_TIME = 500\n",
    "    TEST_TIME = 20\n",
    "\n",
    "    '''% we are going to model the world as a set of N continuous-valued features.\n",
    "    % we will model observations of states of the world as samples from N\n",
    "    % Gaussians with time-varying means and fixed variance. For simplicity,\n",
    "    % assume that agents change nothing in the world.\n",
    "\n",
    "    % first fix the presentation schedule; I am assuming its random'''\n",
    "\n",
    " \n",
    "    \n",
    "    schedule_load = ENCODING_TIME/np.median(np.diff(schedule))                ##% variable important for parts 2,3 of assignment\n",
    "    encoding = np.zeros((N_ITEMS,N_WORLD_FEATURES+1))\n",
    "\n",
    "    world_m = np.array([5, 3, 1, 5, 1]) ##Fixed initial world means for which we get nearly average success rate of 7\n",
    "    \n",
    "    world_var = 1\n",
    "    beta_param = 0.001                ## % what does this parameter affect? Weight of new sampled world features values in new world state \n",
    "    m = 0\n",
    "\n",
    "    world = np.array([0]*5)## Initial world state\n",
    "\n",
    "    \n",
    "    ##% simulating encoding\n",
    "    ogdelta = []\n",
    "    for time in range(1,ENCODING_TIME+1):\n",
    "        delta = compdelta()\n",
    "        ogdelta.append(delta)\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        ##% any item I want to encode in memory, I encode in association with the\n",
    "        ##% state of the world at that time.\n",
    "        if m<N_ITEMS :\n",
    "            if(time==schedule[m]):\n",
    "                encoding[m,:] = np.append(world,m)            ##% encode into the encoding vector\n",
    "                m =  m + 1\n",
    "    ogdelta = np.array([[o] for o in ogdelta])       \n",
    "    gmm = GaussianMixture(n_components=2, covariance_type='spherical',tol=1e-10,weights_init = [0.5,0.5], means_init = [[0],[3]],precisions_init = [0.25,0.75])\n",
    "    gmm.fit(ogdelta)\n",
    "    mu = gmm.means_\n",
    "    var = gmm.covariances_\n",
    "    w = gmm.weights_\n",
    " \n",
    "    ##% simulating retrieval using SAM, but with a bijective image-item mapping\n",
    "\n",
    "    out = [0]*TEST_TIME\n",
    "    while(time<ENCODING_TIME+TEST_TIME):\n",
    "        delta = compdelta2(mu[0],var[0],w[0],mu[1],var[1],w[1])\n",
    "        world_m = world_m + delta\n",
    "        temp = world_m + world_var*np.random.randn(N_WORLD_FEATURES)\n",
    "        prod = np.dot(temp,world)\n",
    "        p = (1+(beta_param**2)*((prod**2)-1))**0.5 - beta_param*prod\n",
    "        world = p*world + beta_param*temp\n",
    "        soa = [0]*N_ITEMS\n",
    "        for m in range(N_ITEMS):\n",
    "        \n",
    "            soa[m] = np.dot(encoding[m,:5], world)    ## % finding association strengths\n",
    "\n",
    "        soa = soa/np.sum(soa)                                                                ## % normalize\n",
    "        out[time-ENCODING_TIME] = np.where(drawFromADist(soa)==1)\n",
    "       \n",
    "        time = time + 1\n",
    "    \n",
    "    success= np.unique(out)     ##% success is number of unique retrievals\n",
    "\n",
    "\n",
    "    return schedule_load, len(success)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97a3da",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-03T18:41:02.953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Single Trial \n",
      "2. Multiple Trials \n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schlist = schedulelist()\n",
    "schload = []\n",
    "sch = []\n",
    "succ = []\n",
    "ch = input('1. Single Trial \\n2. Multiple Trials \\n')\n",
    "print()\n",
    "if(ch == '1'):\n",
    "    for schedule in schlist:\n",
    "        schedule_load, nunique = tcm(schedule)\n",
    "        print('Schedule: ',schedule)\n",
    "        print('No of unique retrivals :', nunique)\n",
    "        print('Scheduling load : ',schedule_load)\n",
    "        print()\n",
    "        if nunique >= 7:\n",
    "            schload.append(schedule_load)\n",
    "            sch.append(schedule)\n",
    "            succ.append(nunique)\n",
    "        \n",
    "    print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "    minload = np.argmin(schload)\n",
    "    print('Schedule :',sch[minload])\n",
    "    print('Schedule Load :',schload[minload])\n",
    "    print('No of unique retrivals :', succ[minload])\n",
    "        \n",
    "\n",
    "elif(ch == '2'):\n",
    "     \n",
    "    for schedule in schlist: \n",
    "        tempsch = 0\n",
    "        uniq= []\n",
    "        for i in range(100):\n",
    "            schedule_load, nunique = tcm(schedule)\n",
    "            tempsch= schedule_load\n",
    "            uniq.append(nunique)\n",
    "         \n",
    "        print('Schedule:',schedule)\n",
    "        print('Schedule Load :',tempsch)\n",
    "        print('Mean Unique Retrivals :', np.mean(uniq))\n",
    "        print()\n",
    "        if np.mean(uniq) >= 7:\n",
    "            schload.append(schedule_load)\n",
    "            sch.append(schedule)\n",
    "            succ.append(np.mean(uniq))\n",
    "            \n",
    "    print('\\n\\n\\nSchedule with lowest schedule load and average success retrival rate atleast  7')\n",
    "    minload = np.argmin(schload)\n",
    "    print('Schedule :',sch[minload])\n",
    "    print('Schedule Load :',schload[minload])\n",
    "    print('Mean No of unique retrivals :', succ[minload])\n",
    "         \n",
    "else:\n",
    "    print('Invalid Choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c5cf2",
   "metadata": {},
   "source": [
    "### It is observed after repetitive experimentation with above code that a schedule with \n",
    "\n",
    "#### (i) 5 big differences (in range 91 to 95) at beginning of schedule and 4 small differences (in range 10 to 5) at the end generally gives  an average success retrival rate of greater than equal to 7\n",
    "\n",
    "#### [1, 95, 189, 283, 377, 471, 478, 485, 492, 499] gives average success rate above 7 in most iterations\n",
    "\n",
    "#### (ii) 4 small differences (in range 7 to 10) at beginning of schedule and 5 big differences (in range 95 to 91) at end generally gives an averafe success retrival rate of gretaer than equal to 7\n",
    "\n",
    "#### [1, 9, 17, 25, 33, 126, 219, 312, 405, 498] gives average success rate above 7 in most iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
